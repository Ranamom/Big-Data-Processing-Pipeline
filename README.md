# Big Data Processing Pipeline

Program was implemented using Python, Twitter API, Kafka, MongoDB, and Tableau. Refer the report for further implementation details:
<a href="https://github.com/chandnii7/SegNet/blob/main/Doc/Project_Report.pdf">View Report</a>
<br/><br/>

### Architecture<br/>
Overview:
* Twitter API is leveraged to obtain information to be processed
* Kafka takes the data and connects the various other components of this pipeline
* MongoDB stores the obtained tweets for later analysis 
* Tableau creates meaningful visualizations
<br/>
<img src="https://github.com/chandnii7/SegNet/blob/main/Data/img2.jpg" height="300" width="450"/>
<br/><br/>

### Results:
Firstly, upon examining the visualizations we see a relative concentration of tweets containing the COVID hashtag in the Americas, Europe, and Southern Asia, this seems to line up with expectations of areas that both have a high adoption of twitter and many Covid-19 cases.  Further work needs to be done to validate this conclusion though.
<br/>
<img src="https://github.com/chandnii7/SegNet/blob/main/Data/img3.jpg" height="300" width="700"/>
<br /><br/>
